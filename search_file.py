import os
import pandas as pd
import faiss
import numpy as np
from sentence_transformers import SentenceTransformer
import streamlit as st

def search_files(query):
    # FAISS ì¸ë±ìŠ¤ ë° í´ëŸ¬ìŠ¤í„°ë§, ë©”íƒ€ë°ì´í„° íŒŒì¼ ê²½ë¡œ
    UPLOAD_FOLDER = './uploads'
    OUTPUT_FOLDER = './outputs'
    file_metadata_path = os.path.join(OUTPUT_FOLDER, 'file_metadata.csv')
    file_cluster_labels_path = os.path.join(OUTPUT_FOLDER, 'file_cluster_labels.txt')
    file_index_path = os.path.join(OUTPUT_FOLDER, 'file_index.faiss')

    # íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
    if not os.path.exists(file_metadata_path) or not os.path.exists(file_index_path) or not os.path.exists(file_cluster_labels_path):
        st.error("íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë¨¼ì € ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤.")
        return

    # ë©”íƒ€ë°ì´í„° ë¡œë“œ
    metadata = pd.read_csv(file_metadata_path)

    # FAISS ì¸ë±ìŠ¤ ë¡œë“œ
    index = faiss.read_index(file_index_path)

    # í´ëŸ¬ìŠ¤í„° ë ˆì´ë¸” ë¡œë“œ
    clusters = np.loadtxt(file_cluster_labels_path, dtype=int)

    # ëª¨ë¸ ë¡œë”©
    model = SentenceTransformer("all-MiniLM-L6-v2")

    if query:
        # ê²€ìƒ‰ì–´ ì„ë² ë”©
        query_vec = model.encode([query]).astype("float32")

        # ìœ ì‚¬ë„ ê²€ìƒ‰
        D, I = index.search(query_vec, k=5)  # ê°€ì¥ ìœ ì‚¬í•œ 5ê°œ íŒŒì¼ ì°¾ê¸°
        
        # ìœ ì‚¬í•œ íŒŒì¼ ê²°ê³¼ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ì €ì¥
        result_df = []
        for idx, dist in zip(I[0], D[0]):
            fname = metadata.loc[metadata["index_id"] == idx, "file_name"].values[0]
            cluster_name = metadata.loc[metadata["index_id"] == idx, "cluster_name"].values[0]
            similarity = 1 - dist  # ìœ ì‚¬ë„ ê³„ì‚° (1 - ê±°ë¦¬)
            result_df.append({"file_name": fname, "similarity": similarity, "cluster_name": cluster_name})

        # DataFrameìœ¼ë¡œ ë³€í™˜
        result_df = pd.DataFrame(result_df)


        # ìœ ì‚¬ë„ ìˆœìœ¼ë¡œ ì •ë ¬ ë° ì¶œë ¥
        for cluster in result_df['cluster_name'].unique():
            cluster_results = result_df[result_df['cluster_name'] == cluster].sort_values(by="similarity", ascending=False)
            
            for _, row in cluster_results.iterrows():
                st.write(f"{cluster} / {row['file_name']} (ìœ ì‚¬ë„: {row['similarity']*100:.2f}%)")
                
        #for cluster in result_df['cluster_name'].unique():
        #    st.subheader(f"ğŸ—‚ï¸ {cluster} í´ëŸ¬ìŠ¤í„°")
        #    cluster_results = result_df[result_df['cluster_name'] == cluster].sort_values(by="similarity", ascending=False)
            
        #    for _, row in cluster_results.iterrows():
        #        st.write(f"ğŸ“„ {row['file_name']} (ìœ ì‚¬ë„: {row['similarity']:.2f})")
                
        # ìœ ì‚¬ë„ ìˆœìœ¼ë¡œ ì •ë ¬ ë° ì¶œë ¥
        #for cluster in result_df['cluster_name'].unique():
        #    cluster_results = result_df[result_df['cluster_name'] == cluster].sort_values(by="similarity", ascending=False)
        #
        #    st.subheader(f"{cluster}")
            
        #    for _, row in cluster_results.iterrows():
        #        similarity_percent = row['similarity'] * 100 #ìœ ì‚¬ë„ ê³„ì‚°
        #        st.write(f"{cluster} / {row['file_name']} (ìœ ì‚¬ë„: {similarity_percent:.1f}%)")
